{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d532080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GRU, Bidirectional, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01d6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/inigoparra/Desktop/carpeta sin t√≠tulo/clean-master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9c3a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = train_data['text']\n",
    "y_train = train_data['label']\n",
    "X_test = test_data['text']\n",
    "y_test = test_data['label']\n",
    "X_val = val_data['text']\n",
    "y_val = val_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b0d643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lana nabarmentzen bakea demokrazia euskal gizartearen ongizatea lortzeko\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/inigoparra/Desktop/GitHub Repositories/WiBaSets/stopwords.txt', 'r') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "X_train = X_train.apply(preprocess_text)\n",
    "X_test = X_test.apply(preprocess_text)\n",
    "X_val = X_val.apply(preprocess_text)\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac36a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ondarrutar arrazoi bozkatzeko\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'<.*?>', '', text)  \n",
    "    text = re.sub(r'[0-9]', '', text)  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    stop_words = set(stopwords.words('basque'))\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "X_train = X_train.apply(clean_text)\n",
    "X_test = X_test.apply(clean_text)\n",
    "X_val = X_val.apply(clean_text)\n",
    "\n",
    "print(X_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3caacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20500\n",
    "max_len = 100\n",
    "embedding_dim = 300\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "856a2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True,\n",
    "               kernel_regularizer=regularizers.l2(0.02), \n",
    "               recurrent_regularizer=regularizers.l2(0.02))))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(GRU(16))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.00001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6d44133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "215/215 [==============================] - 19s 76ms/step - loss: 9.3239 - accuracy: 0.3312 - val_loss: 9.1109 - val_accuracy: 0.3508\n",
      "Epoch 2/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 8.9069 - accuracy: 0.3531 - val_loss: 8.7048 - val_accuracy: 0.3599\n",
      "Epoch 3/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 8.5106 - accuracy: 0.3646 - val_loss: 8.3180 - val_accuracy: 0.3613\n",
      "Epoch 4/100\n",
      "215/215 [==============================] - 16s 72ms/step - loss: 8.1325 - accuracy: 0.3709 - val_loss: 7.9493 - val_accuracy: 0.3534\n",
      "Epoch 5/100\n",
      "215/215 [==============================] - 16s 72ms/step - loss: 7.7719 - accuracy: 0.3777 - val_loss: 7.5973 - val_accuracy: 0.3534\n",
      "Epoch 6/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 7.4269 - accuracy: 0.3834 - val_loss: 7.2611 - val_accuracy: 0.3521\n",
      "Epoch 7/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 7.0983 - accuracy: 0.3790 - val_loss: 6.9398 - val_accuracy: 0.3547\n",
      "Epoch 8/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 6.7841 - accuracy: 0.3844 - val_loss: 6.6326 - val_accuracy: 0.3547\n",
      "Epoch 9/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 6.4828 - accuracy: 0.3880 - val_loss: 6.3388 - val_accuracy: 0.3573\n",
      "Epoch 10/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 6.1954 - accuracy: 0.3937 - val_loss: 6.0577 - val_accuracy: 0.3547\n",
      "Epoch 11/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 5.9200 - accuracy: 0.3952 - val_loss: 5.7888 - val_accuracy: 0.3547\n",
      "Epoch 12/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 5.6573 - accuracy: 0.3941 - val_loss: 5.5315 - val_accuracy: 0.3534\n",
      "Epoch 13/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 5.4049 - accuracy: 0.4023 - val_loss: 5.2853 - val_accuracy: 0.3573\n",
      "Epoch 14/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 5.1639 - accuracy: 0.4121 - val_loss: 5.0498 - val_accuracy: 0.3599\n",
      "Epoch 15/100\n",
      "215/215 [==============================] - 19s 87ms/step - loss: 4.9332 - accuracy: 0.4033 - val_loss: 4.8246 - val_accuracy: 0.3560\n",
      "Epoch 16/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 4.7124 - accuracy: 0.4112 - val_loss: 4.6093 - val_accuracy: 0.3639\n",
      "Epoch 17/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 4.5020 - accuracy: 0.4099 - val_loss: 4.4035 - val_accuracy: 0.3626\n",
      "Epoch 18/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 4.3003 - accuracy: 0.4038 - val_loss: 4.2070 - val_accuracy: 0.3626\n",
      "Epoch 19/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 4.1090 - accuracy: 0.4064 - val_loss: 4.0194 - val_accuracy: 0.3691\n",
      "Epoch 20/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 3.9244 - accuracy: 0.4071 - val_loss: 3.8403 - val_accuracy: 0.3678\n",
      "Epoch 21/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 3.7504 - accuracy: 0.4138 - val_loss: 3.6696 - val_accuracy: 0.3691\n",
      "Epoch 22/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 3.5824 - accuracy: 0.4147 - val_loss: 3.5070 - val_accuracy: 0.3678\n",
      "Epoch 23/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 3.4250 - accuracy: 0.4084 - val_loss: 3.3522 - val_accuracy: 0.3783\n",
      "Epoch 24/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 3.2725 - accuracy: 0.4170 - val_loss: 3.2050 - val_accuracy: 0.3809\n",
      "Epoch 25/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 3.1308 - accuracy: 0.4145 - val_loss: 3.0651 - val_accuracy: 0.3822\n",
      "Epoch 26/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 2.9934 - accuracy: 0.4148 - val_loss: 2.9323 - val_accuracy: 0.3848\n",
      "Epoch 27/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 2.8637 - accuracy: 0.4217 - val_loss: 2.8064 - val_accuracy: 0.3848\n",
      "Epoch 28/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 2.7409 - accuracy: 0.4141 - val_loss: 2.6871 - val_accuracy: 0.3848\n",
      "Epoch 29/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 2.6247 - accuracy: 0.4249 - val_loss: 2.5743 - val_accuracy: 0.3848\n",
      "Epoch 30/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 2.5149 - accuracy: 0.4148 - val_loss: 2.4677 - val_accuracy: 0.3835\n",
      "Epoch 31/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 2.4114 - accuracy: 0.4249 - val_loss: 2.3672 - val_accuracy: 0.3796\n",
      "Epoch 32/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 2.3135 - accuracy: 0.4167 - val_loss: 2.2724 - val_accuracy: 0.3822\n",
      "Epoch 33/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 2.2215 - accuracy: 0.4249 - val_loss: 2.1833 - val_accuracy: 0.3848\n",
      "Epoch 34/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 2.1349 - accuracy: 0.4260 - val_loss: 2.0995 - val_accuracy: 0.3809\n",
      "Epoch 35/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 2.0528 - accuracy: 0.4361 - val_loss: 2.0210 - val_accuracy: 0.3822\n",
      "Epoch 36/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.9773 - accuracy: 0.4402 - val_loss: 1.9474 - val_accuracy: 0.3809\n",
      "Epoch 37/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.9058 - accuracy: 0.4310 - val_loss: 1.8787 - val_accuracy: 0.3822\n",
      "Epoch 38/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.8388 - accuracy: 0.4330 - val_loss: 1.8145 - val_accuracy: 0.3822\n",
      "Epoch 39/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.7763 - accuracy: 0.4410 - val_loss: 1.7547 - val_accuracy: 0.3809\n",
      "Epoch 40/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.7185 - accuracy: 0.4434 - val_loss: 1.6992 - val_accuracy: 0.3796\n",
      "Epoch 41/100\n",
      "215/215 [==============================] - 16s 76ms/step - loss: 1.6657 - accuracy: 0.4386 - val_loss: 1.6478 - val_accuracy: 0.3809\n",
      "Epoch 42/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.6153 - accuracy: 0.4487 - val_loss: 1.6002 - val_accuracy: 0.3835\n",
      "Epoch 43/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.5685 - accuracy: 0.4501 - val_loss: 1.5561 - val_accuracy: 0.3822\n",
      "Epoch 44/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.5261 - accuracy: 0.4441 - val_loss: 1.5156 - val_accuracy: 0.3822\n",
      "Epoch 45/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.4868 - accuracy: 0.4624 - val_loss: 1.4784 - val_accuracy: 0.3822\n",
      "Epoch 46/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.4498 - accuracy: 0.4703 - val_loss: 1.4443 - val_accuracy: 0.3861\n",
      "Epoch 47/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.4173 - accuracy: 0.4648 - val_loss: 1.4131 - val_accuracy: 0.3901\n",
      "Epoch 48/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.3870 - accuracy: 0.4739 - val_loss: 1.3847 - val_accuracy: 0.3940\n",
      "Epoch 49/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.3584 - accuracy: 0.4802 - val_loss: 1.3589 - val_accuracy: 0.3901\n",
      "Epoch 50/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.3321 - accuracy: 0.4843 - val_loss: 1.3355 - val_accuracy: 0.3861\n",
      "Epoch 51/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.3104 - accuracy: 0.4822 - val_loss: 1.3144 - val_accuracy: 0.3874\n",
      "Epoch 52/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.2870 - accuracy: 0.4920 - val_loss: 1.2953 - val_accuracy: 0.3887\n",
      "Epoch 53/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.2684 - accuracy: 0.4894 - val_loss: 1.2783 - val_accuracy: 0.3953\n",
      "Epoch 54/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.2511 - accuracy: 0.5061 - val_loss: 1.2630 - val_accuracy: 0.3927\n",
      "Epoch 55/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.2349 - accuracy: 0.5070 - val_loss: 1.2495 - val_accuracy: 0.3835\n",
      "Epoch 56/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.2186 - accuracy: 0.5249 - val_loss: 1.2375 - val_accuracy: 0.3848\n",
      "Epoch 57/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.2060 - accuracy: 0.5227 - val_loss: 1.2269 - val_accuracy: 0.3770\n",
      "Epoch 58/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.1929 - accuracy: 0.5384 - val_loss: 1.2176 - val_accuracy: 0.3796\n",
      "Epoch 59/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.1792 - accuracy: 0.5470 - val_loss: 1.2096 - val_accuracy: 0.3809\n",
      "Epoch 60/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.1677 - accuracy: 0.5613 - val_loss: 1.2026 - val_accuracy: 0.3770\n",
      "Epoch 61/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.1560 - accuracy: 0.5623 - val_loss: 1.1966 - val_accuracy: 0.3822\n",
      "Epoch 62/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.1449 - accuracy: 0.5622 - val_loss: 1.1917 - val_accuracy: 0.3783\n",
      "Epoch 63/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.1341 - accuracy: 0.5703 - val_loss: 1.1876 - val_accuracy: 0.3809\n",
      "Epoch 64/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.1230 - accuracy: 0.5828 - val_loss: 1.1846 - val_accuracy: 0.3730\n",
      "Epoch 65/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.1115 - accuracy: 0.5852 - val_loss: 1.1820 - val_accuracy: 0.3757\n",
      "Epoch 66/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.0985 - accuracy: 0.5997 - val_loss: 1.1809 - val_accuracy: 0.3665\n",
      "Epoch 67/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.0842 - accuracy: 0.6013 - val_loss: 1.1798 - val_accuracy: 0.3717\n",
      "Epoch 68/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.0731 - accuracy: 0.6050 - val_loss: 1.1800 - val_accuracy: 0.3678\n",
      "Epoch 69/100\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 1.0569 - accuracy: 0.6137 - val_loss: 1.1810 - val_accuracy: 0.3717\n",
      "Epoch 70/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.0432 - accuracy: 0.6155 - val_loss: 1.1835 - val_accuracy: 0.3534\n",
      "Epoch 71/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.0271 - accuracy: 0.6222 - val_loss: 1.1860 - val_accuracy: 0.3573\n",
      "Epoch 72/100\n",
      "215/215 [==============================] - 16s 74ms/step - loss: 1.0097 - accuracy: 0.6259 - val_loss: 1.1893 - val_accuracy: 0.3717\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90ae4313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       211\n",
      "           1      0.363     0.398     0.380       266\n",
      "           2      0.377     0.620     0.469       287\n",
      "\n",
      "    accuracy                          0.372       764\n",
      "   macro avg      0.247     0.340     0.283       764\n",
      "weighted avg      0.268     0.372     0.308       764\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigoparra/opt/anaconda3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/inigoparra/opt/anaconda3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/inigoparra/opt/anaconda3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_val_pad)\n",
    "y_predict_classes = np.argmax(y_predict, axis=1)\n",
    "print(classification_report(y_val, y_predict_classes, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5dd95204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 15ms/step - loss: 1.1799 - accuracy: 0.3887\n",
      "Test loss: 1.1798779964447021, Test accuracy: 0.38869258761405945\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a33fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
