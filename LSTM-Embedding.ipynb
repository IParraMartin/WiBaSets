{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d532080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GRU, Bidirectional, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01d6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/inigoparra/Desktop/carpeta sin t√≠tulo/clean-master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c3a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = train_data['text']\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data['text']\n",
    "y_test = test_data['label']\n",
    "\n",
    "X_val = val_data['text']\n",
    "y_val = val_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0d643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/inigoparra/Desktop/GitHub Repositories/WiBaSets/stopwords.txt', 'r') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "X_train = X_train.apply(preprocess_text)\n",
    "X_test = X_test.apply(preprocess_text)\n",
    "X_val = X_val.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac36a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irailaren eaj bozkatzea izango herri gisa gizarte gisa aurrera egitea\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)  # Remove mentions and hashtags\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[0-9]', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and emojis\n",
    "    text = text.split()  # Tokenize the text\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "X_train = X_train.apply(clean_text)\n",
    "X_test = X_test.apply(clean_text)\n",
    "X_val = X_val.apply(clean_text)\n",
    "\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3caacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20500\n",
    "max_len = 100\n",
    "embedding_dim = 300\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "856a2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim, input_length=max_len))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(GRU(64, return_sequences=True,\n",
    "               kernel_regularizer=regularizers.l2(0.02), \n",
    "               recurrent_regularizer=regularizers.l2(0.02))))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(GRU(32))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6d44133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "439/439 [==============================] - 20s 40ms/step - loss: 2.6958 - accuracy: 0.3666 - val_loss: 2.2222 - val_accuracy: 0.3513\n",
      "Epoch 2/15\n",
      "439/439 [==============================] - 17s 40ms/step - loss: 1.9017 - accuracy: 0.3808 - val_loss: 1.6558 - val_accuracy: 0.3577\n",
      "Epoch 3/15\n",
      "439/439 [==============================] - 17s 40ms/step - loss: 1.4799 - accuracy: 0.3962 - val_loss: 1.3628 - val_accuracy: 0.3359\n",
      "Epoch 4/15\n",
      "439/439 [==============================] - 18s 40ms/step - loss: 1.2472 - accuracy: 0.4322 - val_loss: 1.2133 - val_accuracy: 0.3718\n",
      "Epoch 5/15\n",
      "439/439 [==============================] - 18s 40ms/step - loss: 1.0231 - accuracy: 0.5711 - val_loss: 1.1954 - val_accuracy: 0.4090\n",
      "Epoch 6/15\n",
      "439/439 [==============================] - 18s 40ms/step - loss: 0.7967 - accuracy: 0.6723 - val_loss: 1.2943 - val_accuracy: 0.4295\n",
      "Epoch 7/15\n",
      "439/439 [==============================] - 18s 40ms/step - loss: 0.6221 - accuracy: 0.7784 - val_loss: 1.4621 - val_accuracy: 0.4051\n",
      "Epoch 8/15\n",
      "439/439 [==============================] - 17s 40ms/step - loss: 0.4820 - accuracy: 0.8585 - val_loss: 1.6800 - val_accuracy: 0.4051\n",
      "Epoch 9/15\n",
      "439/439 [==============================] - 17s 40ms/step - loss: 0.3667 - accuracy: 0.9064 - val_loss: 1.8770 - val_accuracy: 0.3808\n",
      "Epoch 10/15\n",
      "439/439 [==============================] - 17s 40ms/step - loss: 0.3017 - accuracy: 0.9319 - val_loss: 2.0148 - val_accuracy: 0.3962\n",
      "Epoch 11/15\n",
      "439/439 [==============================] - 17s 40ms/step - loss: 0.2548 - accuracy: 0.9467 - val_loss: 2.1280 - val_accuracy: 0.3885\n",
      "Epoch 12/15\n",
      "439/439 [==============================] - 18s 40ms/step - loss: 0.2186 - accuracy: 0.9551 - val_loss: 2.4283 - val_accuracy: 0.3782\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 15\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90ae4313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.268     0.111     0.157       234\n",
      "           1      0.368     0.845     0.513       284\n",
      "           2      0.226     0.027     0.048       262\n",
      "\n",
      "    accuracy                          0.350       780\n",
      "   macro avg      0.287     0.328     0.239       780\n",
      "weighted avg      0.290     0.350     0.250       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_val_pad)\n",
    "y_predict_classes = np.argmax(y_predict, axis=1)\n",
    "print(classification_report(y_val, y_predict_classes, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dd95204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 9ms/step - loss: 2.0049 - accuracy: 0.3679\n",
      "Test loss: 2.00490665435791, Test accuracy: 0.3679354190826416\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a33fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
