<h1 align="center"># WiBaSets</h1>
<h1 align="center"># Basque data for NLP and ML</h1>

<p align="left"> <img src="https://komarev.com/ghpvc/?username=iparramartin&label=Profile%20views&color=0e75b6&style=flat" alt="iparramartin" /> </p>

<p align="left"> <a href="https://twitter.com/iparramartin" target="blank"><img src="https://img.shields.io/twitter/follow/iparramartin?logo=twitter&style=for-the-badge" alt="iparramartin" /></a> </p>

<h3 align="left">Connect with me:</h3>
<p align="left">
<a href="https://twitter.com/iparramartin" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/twitter.svg" alt="iparramartin" height="30" width="40" /></a>
</p>

<h3 align="left">Languages and Tools:</h3>
<p align="left"> <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> </p>





TXT Data
-----------
Master file (master.txt) includes 5,129,348 Basque tokens extracted from news articles, wikipedia pages, book reviews, and more. Feel free to dowload it, clean it, or add more data to the corpus. 

CSV data
-----------
There are several files for developing sentiment analysis models in Basque. I add a trainning, test, and validation files for such purposes. All utterances are labeled as positive (1), negative (-1), or neutral (0). The root of the dataset was retrieved from BasqueGLUE, which was latter expanded with 1,000 tweets. The dataset has been used for several purposes, including Basque word embeddings.

Code
-----------
I include a Basque rule-based lemmatizer. It is still under development, but it shows good results when dealing with simple utterances. New suffixes can be added to the code if needed.

Stopwords
-----------
For data cleaning purposes, a brief stopword list has been added.
